{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark session and Run Spark locally with as many worker threads as logical cores on your local machine\n",
    "# getOrCreate() method - Gets an existing SparkSession or, if there is no existing one, creates a new one based on the options set in this builder. In case an existing SparkSession is returned, the config options specified in this builder will be applied to the existing SparkSession.\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    ".appName(\"application one\")\\\n",
    ".config(\"spark.master\", \"local[*]\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = r\"C:/Users/user/Desktop/SampleSuperstore.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark\\\n",
    "    .read\\\n",
    "    .format(file_type)\\\n",
    "    .option(\"inferSchema\", infer_schema)\\\n",
    "    .option(\"header\", first_row_is_header)\\\n",
    "    .option(\"sep\", delimiter)\\\n",
    "    .load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print selected columns to console\n",
    "df.select(\"Ship Mode\", \"Segment\", \"Country\", \"City\", \"State\", \"Postal Code\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert spark dataframe to pandas dataframe\n",
    "pd_df = df.toPandas()\n",
    "print(pd_df)\n",
    "print(pd_df.head())\n",
    "print(pd_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('sample_super')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdf = spark.sql(\n",
    "'''select City, SUM(Sales) as Sales\n",
    " from sample_super group by City '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|           City|             Sales|\n",
      "+---------------+------------------+\n",
      "|          Tyler|           347.206|\n",
      "|    Springfield|43054.342000000004|\n",
      "|        Edmonds|2523.6920000000005|\n",
      "|          Tempe|          1070.302|\n",
      "|  Bowling Green|          2077.375|\n",
      "|          Pasco|          2201.112|\n",
      "|         Auburn|          3155.168|\n",
      "|North Las Vegas| 9801.001999999999|\n",
      "|       Thornton|           765.248|\n",
      "|       Palatine|           116.312|\n",
      "|        Phoenix|         11000.257|\n",
      "|     Plainfield|           4526.85|\n",
      "|  Lake Elsinore|            283.92|\n",
      "|     Georgetown|1786.4200000000003|\n",
      "|      Bethlehem|          1689.634|\n",
      "|         Wilson|368.73199999999997|\n",
      "|      Hollywood|          1070.474|\n",
      "|         Monroe|2970.4339999999997|\n",
      "|       Woodland|264.66200000000003|\n",
      "| Pembroke Pines|         1714.3755|\n",
      "+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfdf.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
